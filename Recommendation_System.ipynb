{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xVm8Ne-ShdpJ"
      },
      "source": [
        "# Implementing a recommendation system for recommending movies using collaborative filtering"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AU_q0o_ehWyk",
        "outputId": "5d350d32-c63b-43d2-ca9e-3bb8103a2418"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import zipfile\n",
        "import os\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q_8Sp08Uhipg",
        "outputId": "e3ac959c-e3e9-4816-d064-3e466f5a85e4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Archive:  /content/drive/My Drive/movie_reviews.zip\n",
            "replace /content/drive/My Drive/movies/movie_genres.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: /content/drive/My Drive/movies/movie_genres.csv  \n",
            "replace /content/drive/My Drive/movies/user_reviews.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: /content/drive/My Drive/movies/user_reviews.csv  \n"
          ]
        }
      ],
      "source": [
        "!unzip '/content/drive/My Drive/movie_reviews.zip' -d \"/content/drive/My Drive/movies\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "2tMczNaWhjFf"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "df_genres = pd.read_csv(\"/content/drive/My Drive/movies/movie_genres.csv\")\n",
        "df_ratings = pd.read_csv(\"/content/drive/My Drive/movies/user_reviews.csv\")\n",
        "\n",
        "# Movies x Genres\n",
        "X = df_genres.iloc[:, 2:].values.astype(np.float32)\n",
        "\n",
        "# Users x Movies\n",
        "y = df_ratings.iloc[:, 2:].values.astype(np.float32)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6RyUGQF5hqef"
      },
      "source": [
        "$\\theta$, User Embeddings\n",
        "\n",
        "X, Item (Movie) Embeddings\n",
        "\n",
        "Collaborative filtering: Learn $\\theta$ and X through optimizing:\n",
        "\n",
        "Minimizing the squared loss $\\sum_{(i,j)âˆˆR}(\\theta_i^T x_j - y_{ij})^2$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "FG-mRX92hmPo"
      },
      "outputs": [],
      "source": [
        "def train_test_split(ratings: torch.Tensor, split_ratio: float = 0.8):\n",
        "    user_idx, movie_idx = ratings.nonzero(as_tuple=True)\n",
        "    all_pairs = torch.stack([user_idx, movie_idx], dim=1)\n",
        "\n",
        "    # Shuffle the indices\n",
        "    num_ratings = all_pairs.size(0)\n",
        "    permutation = torch.randperm(num_ratings)\n",
        "    all_pairs = all_pairs[permutation]\n",
        "\n",
        "    # Train-test split\n",
        "    train_size = int(split_ratio * num_ratings)\n",
        "    train_pairs = all_pairs[:train_size]\n",
        "    test_pairs  = all_pairs[train_size:]\n",
        "\n",
        "    # Create train and test matrices\n",
        "    r_train = torch.zeros_like(ratings)\n",
        "    r_test  = torch.zeros_like(ratings)\n",
        "\n",
        "    r_train[train_pairs[:, 0], train_pairs[:, 1]] = ratings[train_pairs[:, 0], train_pairs[:, 1]]\n",
        "    r_test[test_pairs[:, 0], test_pairs[:, 1]] = ratings[test_pairs[:, 0], test_pairs[:, 1]]\n",
        "\n",
        "    # Ensure every user has at least one rating in train set\n",
        "    unique_users_in_train = set(train_pairs[:, 0].tolist())\n",
        "    all_users = set(user_idx.tolist())\n",
        "\n",
        "    missing_users = all_users - unique_users_in_train\n",
        "    for user in missing_users:\n",
        "        user_ratings = (user_idx == user).nonzero(as_tuple=True)[0]\n",
        "        first_rating_idx = user_ratings[0]  # Take at least one rating from test\n",
        "        r_train[user_idx[first_rating_idx], movie_idx[first_rating_idx]] = ratings[user_idx[first_rating_idx], movie_idx[first_rating_idx]]\n",
        "        r_test[user_idx[first_rating_idx], movie_idx[first_rating_idx]] = 0  # Remove from test\n",
        "\n",
        "    return r_train, r_test\n",
        "\n",
        "# convert to tensors. collaborative filtering will only use user_reviews\n",
        "user_reviews = torch.tensor(y)\n",
        "movie_genres = torch.tensor(X)\n",
        "\n",
        "r_train, r_test = train_test_split(user_reviews, split_ratio=0.8)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WfLcCEoLhsFl",
        "outputId": "8ae21efc-c75c-45b1-b255-b94f5e5d9447"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 0/10000 - Loss: 15.5807\n",
            "Epoch 1000/10000 - Loss: 0.4078\n",
            "Epoch 2000/10000 - Loss: 0.3129\n",
            "Epoch 3000/10000 - Loss: 0.2868\n",
            "Epoch 4000/10000 - Loss: 0.2717\n",
            "Epoch 5000/10000 - Loss: 0.2660\n",
            "Epoch 6000/10000 - Loss: 0.2628\n",
            "Epoch 7000/10000 - Loss: 0.2611\n",
            "Training completed.\n"
          ]
        }
      ],
      "source": [
        "class Recommender(torch.nn.Module):\n",
        "  def __init__(self, num_users, num_movies, num_features):\n",
        "    super(Recommender, self).__init__()\n",
        "\n",
        "    # vectors for users- and movies latent features\n",
        "    self.user_embeddings = torch.nn.Embedding(num_users, num_features)\n",
        "    self.movie_embeddings = torch.nn.Embedding(num_movies, num_features)\n",
        "\n",
        "    # bias terms to capture systematic patterns\n",
        "    self.user_bias = torch.nn.Embedding(num_users, 1)\n",
        "    self.movie_bias = torch.nn.Embedding(num_movies, 1)\n",
        "    self.global_bias = torch.nn.Parameter(torch.tensor(0.0))\n",
        "\n",
        "    # initialize with a normal distribution\n",
        "    torch.nn.init.normal_(self.user_embeddings.weight, std=0.01)\n",
        "    torch.nn.init.normal_(self.movie_embeddings.weight, std=0.01)\n",
        "\n",
        "  def forward(self, user_ids, movie_ids):\n",
        "\n",
        "    # get the vector with latent features\n",
        "    user_vector = self.user_embeddings(user_ids)\n",
        "    movie_vector = self.movie_embeddings(movie_ids)\n",
        "\n",
        "    # interactions between users and movies\n",
        "    dot_product = (user_vector * movie_vector).sum(1)\n",
        "\n",
        "    # get biases\n",
        "    user_b = self.user_bias(user_ids).squeeze(1)\n",
        "    movie_b = self.movie_bias(movie_ids).squeeze(1)\n",
        "\n",
        "    # predicted rating\n",
        "    return dot_product + user_b + movie_b + self.global_bias\n",
        "\n",
        "\n",
        "num_users = y.shape[0]\n",
        "num_movies = X.shape[0]\n",
        "num_features = 32 # latent features\n",
        "\n",
        "model = Recommender(num_users, num_movies, num_features)\n",
        "loss = torch.nn.MSELoss()\n",
        "# stochastic gradient descent with l2 regularization\n",
        "optimizer = torch.optim.Adam( #stochastic gradient descent\n",
        "    model.parameters(),\n",
        "    lr = 0.001,\n",
        "    weight_decay = 0.0005)\n",
        "\n",
        "user_idx, movie_idx = r_train.nonzero(as_tuple=True)\n",
        "ratings = r_train[user_idx, movie_idx]  # get actual ratings\n",
        "\n",
        "losses = []\n",
        "epochs = 10000\n",
        "best_loss = float(\"inf\")\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    y_pred = model(user_idx, movie_idx)\n",
        "\n",
        "    loss_value = loss(y_pred, ratings)\n",
        "\n",
        "    if loss_value < best_loss:\n",
        "      best_loss = loss_value\n",
        "      losses.append(loss_value.item())\n",
        "    else:\n",
        "      break\n",
        "\n",
        "    loss_value.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if epoch % 1000 == 0:\n",
        "        print(f\"Epoch {epoch}/{epochs} - Loss: {loss_value.item():.4f}\")\n",
        "\n",
        "print(\"Training completed.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SpBoDvGKi4fu",
        "outputId": "c8503566-5730-4410-e4f7-73c3d49f7746"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Loss (MSE): 1.7051\n",
            "Test RMSE: 1.3058\n"
          ]
        }
      ],
      "source": [
        "# Evaluate on the test set\n",
        "model.eval()  # Set model to evaluation mode\n",
        "with torch.no_grad():\n",
        "    user_idx_test, movie_idx_test = r_test.nonzero(as_tuple=True)  # Get nonzero test ratings\n",
        "    ratings_test = r_test[user_idx_test, movie_idx_test]  # Get actual ratings\n",
        "\n",
        "    y_pred_test = model(user_idx_test, movie_idx_test)  # Predict ratings\n",
        "\n",
        "    test_loss = loss(y_pred_test, ratings_test)  # Compute loss\n",
        "    print(f\"Test Loss (MSE): {test_loss.item():.4f}\")\n",
        "    print(f\"Test RMSE: {test_loss.sqrt().item():.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6xU6CfsKoPbO",
        "outputId": "03daffe6-ec63-4f06-e4cb-786f657e558a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Top 5 recommendations for Vincent: ['Homefront', 'Alpha and Omega 4: The Legend of the Saw Toothed Cave', 'The Cabin in the Woods', 'Harry Potter and the Chamber of Secrets', 'Jaws']\n",
            "\n",
            "Top 5 recommendations for Edgar: ['The Magic Sword: Quest for Camelot', 'Force 10 from Navarone', 'Jonah: A VeggieTales Movie', 'Dylan Dog: Dead of Night', 'Wasabi']\n",
            "\n",
            "Top 5 recommendations for Addilyn: ['Bottle Rocket', 'Last Action Hero', 'Alexander', 'The Tempest', \"Perrier's Bounty\"]\n",
            "\n",
            "Top 5 recommendations for Marlee: ['Max Payne', 'Homefront', 'Harley Davidson and the Marlboro Man', 'Bottle Rocket', 'The Good Thief']\n",
            "\n",
            "Top 5 recommendations for Javier: ['Seeking a Friend for the End of the World', 'Chill Factor', 'Arthur Christmas', 'Monster House', 'Good Dick']\n",
            "\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# get the index for movies so that we can get the titles\n",
        "movie_index_to_name = {idx: title for idx, title in enumerate(df_genres[\"movie_title\"].tolist())}\n",
        "\n",
        "def recommend_movies(model, user_id, top_k=5):\n",
        "    num_movies = len(movie_index_to_name)\n",
        "\n",
        "    # predict movie ratings for a user:\n",
        "    # create tensors for: repeat user id for each movie and movie indices\n",
        "    user_tensor = torch.tensor([user_id] * num_movies)\n",
        "    movie_tensor = torch.tensor(list(range(num_movies)))\n",
        "\n",
        "    # get predicted ratings for all movies\n",
        "    #model.eval()\n",
        "    with torch.no_grad():\n",
        "        predicted_ratings = model(user_tensor, movie_tensor)\n",
        "\n",
        "    # Mask already rated movies\n",
        "    rated_mask = y[user_id] > 0  # Mask for rated movies\n",
        "    predicted_ratings[rated_mask] = -float(\"inf\")  # Set to lowest value\n",
        "\n",
        "\n",
        "    # get top K movie indices\n",
        "    top_movie_indices = predicted_ratings.argsort(descending=True)[:top_k]\n",
        "\n",
        "    # convert movie indices to names\n",
        "    recommended_movies = [movie_index_to_name[idx.item()] for idx in top_movie_indices]\n",
        "\n",
        "    return recommended_movies\n",
        "\n",
        "user_names = [\"Vincent\", \"Edgar\", \"Addilyn\", \"Marlee\", \"Javier\"]\n",
        "user_index = {name: idx for idx, name in enumerate(user_names)}\n",
        "\n",
        "for user in user_names:\n",
        "    user_id = user_index[user]  # Convert name to index\n",
        "    top_movies = recommend_movies(model, user_id, top_k=5)\n",
        "    print(f\"Top 5 recommendations for {user}: {top_movies}\")\n",
        "    print(\"\")\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
